{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHgmxWG_7lnE"
   },
   "source": [
    "# Введение в анализ данных\n",
    "## НИУ ВШЭ, 2019-2020 учебный год\n",
    "\n",
    "### Домашнее задание №3\n",
    "\n",
    "Задание выполнил(а): Бир Анастасия\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 09.04.2020\n",
    "\n",
    "Дедлайн: 24.04.2020 23:59 MSK\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом домашнем задании вы будете работать с линейной классификацией, попрактикуетесь на реальной задаче классификации текстов.\n",
    "\n",
    "Для решения этого домашнего задания намного удобнее будет использовать Colab, так как данных много.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "За сдачу задания позже срока на итоговую оценку за задание накладывается штраф в размере 1 балл в день, но получить отрицательную оценку нельзя.\n",
    "\n",
    "__Внимание!__ Домашнее задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов.\n",
    "\n",
    "### Формат сдачи\n",
    "Загрузка файлов с решениями происходит в системе Anytask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztx03xvr9T95"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "BVrrwTJNjuDt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "_VMchexbjjTh",
    "outputId": "c1f66a1f-8851-42f3-e7e5-6c48d3c24707",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Датасет можно скачать здесь\n",
    "\n",
    "!wget https://www.dropbox.com/s/tg55q9mrziroyrs/train_subset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvXKae8q9nn-"
   },
   "source": [
    "### Данные\n",
    "\n",
    "Мы имеем дело с данными с торговой платформы Avito.\n",
    "Для каждого товара представлены следующие параметры:\n",
    " - title\n",
    " - description\n",
    " - Category_name\n",
    " - Category\n",
    "\n",
    "Имеется информация об объектах 50 классов.\n",
    "Задача: по новым объектам (title, description) предсказать Category.\n",
    "(Очевидно, что параметр Category_name для предсказания классов использовать нельзя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "BqEuoDhqNgoa",
    "outputId": "b345f049-ae77-4d1b-a25f-4d4f447e63d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>Category_name</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382220</th>\n",
       "      <td>Прихожая</td>\n",
       "      <td>В хорошем состоянии. Торг</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397529</th>\n",
       "      <td>Кордиант 215/55/16 Летние</td>\n",
       "      <td>Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584569</th>\n",
       "      <td>Стол</td>\n",
       "      <td>Стол, 2 рабочих места . Стол серого цвета, в д...</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513100</th>\n",
       "      <td>Комбинезон</td>\n",
       "      <td>Размер-42/44</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091886</th>\n",
       "      <td>Ветровка</td>\n",
       "      <td>На 2 года</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "id                                   \n",
       "382220                    Прихожая   \n",
       "397529   Кордиант 215/55/16 Летние   \n",
       "584569                        Стол   \n",
       "2513100                 Комбинезон   \n",
       "1091886                   Ветровка   \n",
       "\n",
       "                                               description  \\\n",
       "id                                                           \n",
       "382220                           В хорошем состоянии. Торг   \n",
       "397529   Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...   \n",
       "584569   Стол, 2 рабочих места . Стол серого цвета, в д...   \n",
       "2513100                                       Размер-42/44   \n",
       "1091886                                          На 2 года   \n",
       "\n",
       "                     Category_name  Category  \n",
       "id                                            \n",
       "382220           Мебель и интерьер        20  \n",
       "397529       Запчасти и аксессуары        10  \n",
       "584569           Мебель и интерьер        20  \n",
       "2513100  Одежда, обувь, аксессуары        27  \n",
       "1091886     Детская одежда и обувь        29  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train_subset.csv\", index_col='id')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "Kg8iPp7fiwGh",
    "outputId": "96ed00ed-b63b-4478-f2d4-66bda1110b5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 4)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "A1hvzAMETU2d"
   },
   "outputs": [],
   "source": [
    "X = data[['title', 'description']].to_numpy()\n",
    "y = data['Category'].to_numpy()\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMYU7zZw_cw-"
   },
   "source": [
    "Сразу разделим выборку на train и test.\n",
    "Никакие данные из test для обучения использовать нельзя!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "6fia4_3vNprp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "qDR8LtTJUIGt",
    "outputId": "fd4d5b55-a023-4129-9ff5-a6e8e24db915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Сапоги 46 размер новые', 'Сапоги 46 размер новые'],\n",
       "       ['Светильники потолочный swarovski',\n",
       "        'светильники потолочные swarovski 6 штук , цена за штуку. В эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n",
       "       ['iPhone 7 plus 128GB Red красный в наличии',\n",
       "        '\\xa0/\\n/\\n Данная цена только для подписчиков Instagram: iQmac/\\n/\\n Новый красный айфон 7 Plus в наличии это элегантный и мощный смартфон, который готов в полной мере раскрыть новые возможности iOS 10. Аппарат с 4-ядерным процессором А10 и 3 ГБ ОЗУ с легкостью решает самые ресурсоемкие задачи, позволяя наслаждаться быстродействием «тяжелых» приложений и игр на 5,5-дюймовом дисплее. Аппарат получил экран, как у iPad Pro, так что картинка теперь соответствует кинематографическому стандарту.'],\n",
       "       ['Пион Ирис Ромашка рассада',\n",
       "        'Пион куст 500 р ( более 10 шт)/\\nСаженец/ корень 100р/\\nРастут у нас более 70 лет/\\nРозовые, бордовые и белые/\\nНа фото цветы 2018г/\\nП. Зубчаниновка/\\nлибо пл. Революции/\\nЕсть ирисы, ромашка, клубника, боярышник и ирга'],\n",
       "       ['Кофта', 'Состояние отличное']], dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-ZEdlEGAXTD"
   },
   "source": [
    "### Токенизация (1 балл)\n",
    "\n",
    "\n",
    "Токенизация -- разбиение текста на мелкие части, которые можно обработать машинными методами.\n",
    "Можно использовать разные алгоритмы токенизации.\n",
    "Давайте пока остановимся на простом WordPunctTokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "O9VgNlZ1Qy3o",
    "outputId": "59ef3a75-008e-47c5-fba8-a319eba13ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...\n",
      "after: здраствуйте . я , кирилл . хотел бы чтобы вы сделали игру , 3д - экшон суть такова ...\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    return ' '.join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "\n",
    "text = 'Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...'\n",
    "print(\"before:\", text,)\n",
    "print(\"after:\", preprocess(text),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_RYBKC26o1X"
   },
   "source": [
    "__Задание:__ Токенизируйте title и description в train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "Z5WO-7tJUvbs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21000/21000 [00:00<00:00, 31008.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(X_train):\n",
    "    for i, item in enumerate(row):\n",
    "        row[i] = preprocess(row[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['сапоги 46 размер новые', 'сапоги 46 размер новые'],\n",
       "       ['светильники потолочный swarovski',\n",
       "        'светильники потолочные swarovski 6 штук , цена за штуку . в эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n",
       "       ['iphone 7 plus 128gb red красный в наличии',\n",
       "        '/ / данная цена только для подписчиков instagram : iqmac / / новый красный айфон 7 plus в наличии это элегантный и мощный смартфон , который готов в полной мере раскрыть новые возможности ios 10 . аппарат с 4 - ядерным процессором а10 и 3 гб озу с легкостью решает самые ресурсоемкие задачи , позволяя наслаждаться быстродействием « тяжелых » приложений и игр на 5 , 5 - дюймовом дисплее . аппарат получил экран , как у ipad pro , так что картинка теперь соответствует кинематографическому стандарту .'],\n",
       "       ['пион ирис ромашка рассада',\n",
       "        'пион куст 500 р ( более 10 шт )/ саженец / корень 100р / растут у нас более 70 лет / розовые , бордовые и белые / на фото цветы 2018г / п . зубчаниновка / либо пл . революции / есть ирисы , ромашка , клубника , боярышник и ирга'],\n",
       "       ['кофта', 'состояние отличное'],\n",
       "       ['1 - к квартира , 33 м² , 4 / 5 эт .',\n",
       "        'продаётся уютная , тёплая квартира в экологически - чистом районе города , рядом сосновый бор , всегда чистый воздух . дом 2004 г ., хорошие соседи , на площадке 2 - е квартиры , развитая инфраструктура , в шаговой доступности поликлиника , школа , тк « орбита », вещевой рынок . квартира в хорошем состоянии . подходит под ипотеку , долгов , обременений , перепланировке нет . в квартире натяжные потолки , в ванной комнате стены выполнены из влагостойких стеновых панелей . возможен обмен на квартиру в г . магнитогорске , торг .'],\n",
       "       ['платье новое 60 размера',\n",
       "        'платье 60 размера , новое , красивого темно синего цвета , из трикотажной ткани : вискоза 95 %, эластина 5 % . а - образного силуэта с рукавом 2 / 3 . длинна по спинке 113см .'],\n",
       "       ['ваз 2114 samara , 2007',\n",
       "        'продам ваз 2114 2007 г . в . в хорошем состоянии . / 2 владельца , птс оригинал . / машина в родной краске , в дтп никогда не была ,/ днище целое не ржавое . по ходовой нареканий нет , сел и поехал . / имеется музыка , сигнализация 2 комплекта ключей , птф , передние стеклоподъемники ./ небольшой торг при осмотре . / обмен не интересует .'],\n",
       "       ['наушники блутус',\n",
       "        'долго держат заряд 4 - 5 часов , можно и больше при средней громкости выжать из них . вкладыши .'],\n",
       "       ['пальто tommy hilfiger',\n",
       "        'состояние нового . промахнулась с размером . пальто до - 10 - 12 градусов . / возможна пересылка по почте']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "VDnDSWwFDwFo"
   },
   "outputs": [],
   "source": [
    "assert X_train[10][1] == 'продам иж планета 3 , 76 год , ( стоит на старом учёте , документы утеряны ) на ходу , хорошее состояние , все интересующие вопросы по телефону ( с родной коляской на 3 тысячи дороже ) . торга не будет .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in X_test:\n",
    "    for i, item in enumerate(row):\n",
    "        row[i] = preprocess(row[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlIITUk0AsmS"
   },
   "source": [
    "### BOW (1.5 балла)\n",
    "\n",
    "Один из традиционных подходов -- построение bag of words.\n",
    "\n",
    "Метод состоит в следующем:\n",
    "\n",
    " - Составить словарь самых часто встречающихся слов\n",
    " - Для каждого примера посчитать, сколько раз каждое слово из словаря в нём встречается\n",
    "\n",
    "\n",
    "В sklearn есть CountVectorizer, но в этом задании его использовать нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMKUttDWIF92"
   },
   "source": [
    "__Задание:__ Найдите 10000 самых частых слов из `title` и `description` обучающей выборки, отсортируйте их по убыванию частотности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "ZEVE_bzkRBx0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393309/1393309 [00:00<00:00, 1855138.13it/s]\n"
     ]
    }
   ],
   "source": [
    "def to_vocabulary(X_train):\n",
    "    data = np.reshape(X_train, newshape=(42000,))\n",
    "    word_list = [word for line in data for word in line.split()]\n",
    "    bow_vocabulary = {}\n",
    "    for row in tqdm(word_list):\n",
    "        if row in bow_vocabulary.keys():\n",
    "            bow_vocabulary[row] += 1\n",
    "        else:\n",
    "            bow_vocabulary[row] = 1\n",
    "    bow_vocabulary = {k: v for k, v in sorted(bow_vocabulary.items(), key=lambda item: item[1], reverse=True)}\n",
    "    del data, word_list\n",
    "    return bow_vocabulary\n",
    "bow_vocabulary = dict(list(to_vocabulary(X_train).items())[0:10000])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "QTs70ZxVbk0J"
   },
   "outputs": [],
   "source": [
    "assert sorted(bow_vocabulary)[::200] == ['!', '12500', '270', '700', 'by', 'gh', 'michael', 'sonata', 'ø', 'аудиоподготовка', 'большим', 'веса', 'воспроизведения', 'габариты', 'гтд', 'джинсами', 'доступность', 'загрузки', 'зимней', 'использовался', 'квартала', 'коммуникации', 'кошки', 'лакированные', 'магазин', 'металл', 'мск', 'натуральным', 'носке', 'одному', 'отвечаем', 'пассат', 'плотно', 'покраску', 'постоянные', 'примеры', 'просьба', 'размещайте', 'репетитор', 'сантехник', 'сидения', 'современного', 'стала', 'схема', 'тон', 'удлиненная', 'фасад', 'цветами', 'шея', 'эту']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "4awkhecbR9om"
   },
   "outputs": [],
   "source": [
    "def text_to_bow(text: str, bow_vocabulary) -> np.array:\n",
    "    result = np.array([0]*len(bow_vocabulary))\n",
    "    for row in text.split():\n",
    "        if row in list(bow_vocabulary.keys()):\n",
    "            result[list(bow_vocabulary.keys()).index(row)] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "IZnJT2JbdXA3"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(np.where(text_to_bow(\"сдаётся уютный , тёплый гараж для стартапов в ml\", bow_vocabulary) != 0)[0],\n",
    "                   np.array([   1,    4,   12,  565,  866, 1601, 2539, 4063])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "HR_D8Fn4pudv"
   },
   "outputs": [],
   "source": [
    "def items_to_bow(items: np.array, bow_vocabulary, use_title=False) -> np.array:\n",
    "    if use_title == False:\n",
    "        result = np.zeros((len(items), len(bow_vocabulary)))\n",
    "        for i in tqdm(range(len(result))):\n",
    "            result[i] = text_to_bow(items[i][1], bow_vocabulary)\n",
    "    else:\n",
    "        result = np.zeros((len(items), len(bow_vocabulary)))\n",
    "        for i in tqdm(range(len(result))):\n",
    "            result[i] = text_to_bow(items[i][0] + ' ' + items[i][1], bow_vocabulary)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "pKdfMqbIetPA",
    "outputId": "9054ba46-57a4-4eea-cb3d-5d1764e1d56f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 63.92it/s]\n"
     ]
    }
   ],
   "source": [
    "assert np.allclose(np.where(items_to_bow([X_train[42]],bow_vocabulary)[0] != 0),\n",
    "                   np.array([   0, 1, 2, 5, 6, 7, 12, 27, 41, 49, 110,\n",
    "                                189,  208,  221, 2032, 3052, 7179, 9568]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "wwOZaEpMSQsZ",
    "outputId": "8a30c3af-3517-42bd-a5f3-36206b4b264a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21000/21000 [06:52<00:00, 50.90it/s]\n",
      "100%|██████████| 9000/9000 [02:53<00:00, 51.95it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_bow = items_to_bow(X_train, bow_vocabulary)\n",
    "X_test_bow = items_to_bow(X_test, bow_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJoXiCWI7VF5"
   },
   "source": [
    "### Логистическая регрессия и SVC (1 балл)\n",
    "\n",
    "\n",
    "Теперь описание каждого товара представлено, как точка в многомерном пространстве.\n",
    "Очень важно запомнить эту идею: дальше мы будем рассматривать разные способы перехода от текста к точке в пространстве.\n",
    "\n",
    "Для BOW каждое измерение в пространстве -- какое-то слово.\n",
    "Мы предполагаем, что текст описывается набором каких-то популярных слов, которые в нём встречаются, а близкие по смыслу тексты будут использовать одинаковые слова.\n",
    "\n",
    "Обучите логистическую регрессию и SVC с базовыми параметрами.\n",
    "\n",
    "**Подсказка: рассмотрите использование sparse-матриц - в них хранятся только ненулевые элементы.** `scipy.sparse.csr_matrix(X_train_bow)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "Ky3HV1rTSS9L",
    "outputId": "612a5f0d-76bd-44f4-eeeb-63b517443797"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7046666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "bow_model_lr = LogisticRegression(max_iter=100)\n",
    "bow_model_lr.fit(X_train_bow, y_train)\n",
    "acc_lr_bow = accuracy_score(bow_model_lr.predict(X_test_bow), y_test)\n",
    "print(acc_lr_bow)\n",
    "\n",
    "assert acc_lr_bow > 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "-c46ZT0lvF6T",
    "outputId": "4b1cb34a-201b-4dc2-9155-fdb6919c6c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6835555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "bow_model_svc = LinearSVC(max_iter=70)\n",
    "bow_model_svc.fit(X_train_bow, y_train)\n",
    "acc_svc_bow = accuracy_score(bow_model_svc.predict(X_test_bow), y_test)\n",
    "print(acc_svc_bow)\n",
    "\n",
    "assert acc_svc_bow > 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwKE57YZ1Hzn"
   },
   "source": [
    "### Модификация признаков (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewMlxQezL6Ax"
   },
   "source": [
    "Постройте признаковое пространство на конкатенации (через пробел) `title` и `description`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "evqKo1r5L5BO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21000/21000 [07:07<00:00, 49.15it/s] \n"
     ]
    }
   ],
   "source": [
    "X_train_mod = items_to_bow(X_train, bow_vocabulary, use_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [06:00<00:00, 56.88it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_mod = items_to_bow(X_test, bow_vocabulary, use_title=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvCAL3qGDByj"
   },
   "source": [
    "### mystem (1.5) балла\n",
    "\n",
    "Как можно заметить, в текстах одни и те же слова могут быть в разных падежах, а соответственно в bow это будут разные признаки. \n",
    "Чтобы исправить это, можно лемматизировать слова - с помощью библиотеки Mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mGvNHfVsDfhq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'здравствовать,, ,ваш, ,благородие,\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(m.lemmatize(\"Здравствуйте, ваше благородие\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ \n",
    "* Лемматезируйте `title` и `description` с помощью mystem\n",
    "* Gостройте BoW-представление\n",
    "* Обучите на нём логистическую регрессию и SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mystem_preprocess(text):\n",
    "    return ' '.join(m.lemmatize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21000/21000 [00:53<00:00, 391.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(X_train):\n",
    "    for i, item in enumerate(row):\n",
    "        row[i] = mystem_preprocess(row[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [00:25<00:00, 351.93it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(X_test):\n",
    "    for i, item in enumerate(row):\n",
    "        row[i] = mystem_preprocess(row[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1431551/1431551 [00:01<00:00, 1122681.10it/s]\n"
     ]
    }
   ],
   "source": [
    "bow_mys_vocabulary = dict(list(to_vocabulary(X_train).items())[0:10000])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21000/21000 [06:53<00:00, 44.58it/s]\n",
      "100%|██████████| 9000/9000 [03:01<00:00, 49.57it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_bow_mys = items_to_bow(X_train, bow_mys_vocabulary)\n",
    "X_test_bow_mys = items_to_bow(X_test, bow_mys_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7273333333333334\n",
      "CPU times: user 1min 55s, sys: 2.05 s, total: 1min 57s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bow_model_lr = LogisticRegression(max_iter=100)\n",
    "bow_model_lr.fit(X_train_bow_mys, y_train)\n",
    "acc_lr_bow = accuracy_score(bow_model_lr.predict(X_test_bow_mys), y_test)\n",
    "print(acc_lr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7066666666666667\n",
      "CPU times: user 5.12 s, sys: 63.2 ms, total: 5.18 s\n",
      "Wall time: 5.24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bow_model_svc = LinearSVC(max_iter=70)\n",
    "bow_model_svc.fit(X_train_bow_mys, y_train)\n",
    "acc_svc_bow = accuracy_score(bow_model_svc.predict(X_test_bow_mys), y_test)\n",
    "print(acc_svc_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXbsPtpfoB7m"
   },
   "source": [
    "### TF-IDF (1.5 балла)\n",
    "\n",
    "Не все слова полезны одинаково, давайте попробуем [взвесить](http://tfidf.com/) их, чтобы отобрать более полезные.\n",
    "\n",
    "\n",
    "> TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "> \n",
    "> IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "\n",
    "В sklearn есть TfidfVectorizer, но в этом задании его использовать нельзя.\n",
    "\n",
    "Давайте для простоты считать один tf-idf для title и description. Для каждого слова из bow_vocabulary нужно посчитать:\n",
    "1. Сколько раз оно встретилось в title и description во всём X_train\n",
    "2. В тексте скольких товаров встретилось это слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(items: np.array) -> np.array:\n",
    "    result = []\n",
    "    for i in range(len(items)):\n",
    "        result.append(items[i][0] + ' ' + items[i][1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_for_tfidf = concat(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_arr(items):\n",
    "    count_arr = {}\n",
    "    for key in tqdm(bow_vocabulary.keys()):\n",
    "        for row in items:\n",
    "            if key in row.split():\n",
    "                if key in count_arr.keys():\n",
    "                    count_arr[key] += 1\n",
    "                else:\n",
    "                    count_arr[key] = 1\n",
    "    return count_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [18:33<00:00,  8.98it/s]\n"
     ]
    }
   ],
   "source": [
    "count_arr = create_count_arr(X_train_for_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "6i5zFpD9rbtz"
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def tf(counter, docs_words_amount):\n",
    "    return counter / docs_words_amount\n",
    "\n",
    "\n",
    "def idf(documents_amount, count_arr, word):\n",
    "    return log(documents_amount / count_arr[word])\n",
    "\n",
    "\n",
    "def text_to_tfidf(text: str, count_arr: dict, documents_amount: int, bow_vocabulary) -> np.array:\n",
    "    result = np.array([0]*len(bow_vocabulary))\n",
    "    for row in text.split():\n",
    "        num_of_docs = 0\n",
    "        if row in list(bow_vocabulary.keys()):\n",
    "            for item in text.split():\n",
    "                if item == row:\n",
    "                    num_of_docs += 1\n",
    "            result[list(bow_vocabulary.keys()).index(row)] = tf(num_of_docs, len(text.split())) * idf(documents_amount, count_arr, row)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_to_tfidf(items: np.array, bow_vocabulary):\n",
    "    result = np.zeros((len(items), len(bow_vocabulary)))\n",
    "    for i in range(len(result)):\n",
    "        result[i] = text_to_tfidf(items[i][1], count_arr, len(items), bow_vocabulary)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf = items_to_tfidf(X_train, bow_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_tfidf = items_to_tfidf(X_test, bow_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YFA-8kE1RHk"
   },
   "source": [
    "### Модели на TF-IDF признаках (1 балл)\n",
    "\n",
    "Обучите логистическую регрессию и SVC, оцените качество (accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7933333333\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_lr = LogisticRegression(max_iter=100)\n",
    "tfidf_model_lr.fit(X_train_tfidf, y_train)\n",
    "acc_lr_tfidf = accuracy_score(tfidf_model_lr.predict(X_test_tfidf), y_test)\n",
    "print(acc_lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.800333339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_svc = LinearSVC(max_iter=70)\n",
    "tfidf_model_svc.fit(X_train_tfidf, y_train)\n",
    "acc_svc_tfidf = accuracy_score(tfidf_model_svc.predict(X_test_tfidf), y_test)\n",
    "print(acc_svc_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFdy3lUFDsOr"
   },
   "source": [
    "### Hashing Vectorizer (0.5 балла)\n",
    "\n",
    "Попробуйте использовать `sklearn.feature_extraction.text.HashingVectorizer` для векторизации текстов.\n",
    "Обязательно оцените качество работы алгоритмов классификации с использованием новой векторизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "Y666HTrqDq1m"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_vector = HashingVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concat = concat(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_concat = concat(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hash = hash_vector.fit_transform(X_train_concat)\n",
    "X_test_hash = hash_vector.fit_transform(X_test_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7236666666666667\n",
      "CPU times: user 46.5 s, sys: 1.6 s, total: 48.1 s\n",
      "Wall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bow_model_lr = LogisticRegression(max_iter=100)\n",
    "bow_model_lr.fit(X_train_hash, y_train)\n",
    "acc_lr_bow = accuracy_score(bow_model_lr.predict(X_test_hash), y_test)\n",
    "print(acc_lr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n",
      "CPU times: user 3.73 s, sys: 281 ms, total: 4.01 s\n",
      "Wall time: 4.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bow_model_svc = LinearSVC(max_iter=70)\n",
    "bow_model_svc.fit(X_train_hash, y_train)\n",
    "acc_svc_bow = accuracy_score(bow_model_svc.predict(X_test_hash), y_test)\n",
    "print(acc_svc_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Vectors (1.5 балл)\n",
    "\n",
    "Давайте попробуем другой подход -- кажому слову сопоставим какой-то эмбеддинг (вектор).\n",
    "\n",
    "Вектора будут небольшой размерности. Таким образом мы снизим количество параметров в модели.\n",
    "\n",
    "Вектора мы возьмём уже готовые (обученные на текстах их интернета), так что наша модель будет знать некоторую дополнительную информацию о внешнем мире."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "sy2TXmQ2jZSY"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.wrappers import FastText\n",
    "\n",
    "model = FastText.load_fasttext_format('ru.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "H49QR_jhjmCa"
   },
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence: str) -> np.array:\n",
    "    embedding_dim = model['привет'].shape[0]\n",
    "    features = np.zeros([embedding_dim], dtype='float32')\n",
    "    for word in sentence.split():\n",
    "        if word in model:\n",
    "            features += model[word]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Gj6U_hjtlllV"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml')[::50],\n",
    "                   np.array([ 0.08189847,  0.07249198, -0.15601222,  0.03782297,  0.09215296, -0.23092946]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ \n",
    "* Обучите логистическую регрессию и SVM на новых признаках\n",
    "* Оцените качество (accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_embedding(items: np.array, use_title=False) -> np.array:\n",
    "    result = []\n",
    "    if use_title == False:\n",
    "        for i in tqdm(range(len(items))):\n",
    "            result.append(sentence_embedding(items[i][1]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21000/21000 [00:21<00:00, 993.21it/s] \n"
     ]
    }
   ],
   "source": [
    "X_train_embedd = items_embedding(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [00:07<00:00, 1239.80it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_embedd = items_embedding(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5603333333333333\n",
      "CPU times: user 5min 12s, sys: 3.04 s, total: 5min 15s\n",
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bow_model_lr = LogisticRegression(max_iter=100)\n",
    "bow_model_lr.fit(X_train_embedd, y_train)\n",
    "acc_lr_bow = accuracy_score(bow_model_lr.predict(X_test_embedd), y_test)\n",
    "print(acc_lr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5143333333333333\n",
      "CPU times: user 39.6 s, sys: 242 ms, total: 39.8 s\n",
      "Wall time: 40.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bow_model_svc = LinearSVC(max_iter=70)\n",
    "bow_model_svc.fit(X_train_embedd, y_train)\n",
    "acc_svc_bow = accuracy_score(bow_model_svc.predict(X_test_embedd), y_test)\n",
    "print(acc_svc_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVEdlFostSnX"
   },
   "source": [
    "### Что дальше?\n",
    "\n",
    "Решение каждого пункта 2 балла:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. N-Gram модели текстовой классификации\n",
    "    * Признаки - mystem\n",
    "    * n-gramm'ы - несколько слов подряд объединяются в один токен\n",
    "    * Модели - только логистическая регрессия\n",
    "    * Настоятельно рекомендуется использовать sparse-матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21000/21000 [00:50<00:00, 416.33it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(X_train):\n",
    "    for i, item in enumerate(row):\n",
    "        row[i] = mystem_preprocess(row[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [00:23<00:00, 384.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(X_test):\n",
    "    for i, item in enumerate(row):\n",
    "        row[i] = mystem_preprocess(row[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vector = word_vec.fit_transform(concat(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vector = word_vec.fit_transform(concat(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20855555555555555\n",
      "CPU times: user 15.3 s, sys: 105 ms, total: 15.4 s\n",
      "Wall time: 7.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec_model_lr = LogisticRegression(max_iter=100)\n",
    "vec_model_lr.fit(X_train_vector, y_train)\n",
    "acc_lr_vec = accuracy_score(vec_model_lr.predict(X_test_vector), y_test)\n",
    "print(acc_lr_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Использовать Vowpal Wabbit вместо sklearn\n",
    "    * Признаки - обычный BoW title+description \n",
    "    * Главный вызов - заставить работать библиотеку и подготовить признаки"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Эта либа - исчадие ада.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Другие способы лемматизации (pymorphy2, spaCy)\n",
    "\n",
    "\n",
    "* Снабжайте код пояснениями;\n",
    "* Обязательно необходимо написать вывод по каждому пункту, который вы реализуете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В pymorphy2 для морфологического анализа слов есть класс MorphAnalyzer. По дефолту уже стоит русский язык"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пишем функцию для лемматизации, будем все приводить к нормальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pymorph_lem(items):\n",
    "    result = []\n",
    "    for row in tqdm(items):\n",
    "        for item in row:\n",
    "            line = []\n",
    "            for word in item.split():\n",
    "                line.append(morph.parse(word)[0].normal_form)\n",
    "            result.append(line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну, собственно применяем функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21000/21000 [03:02<00:00, 114.85it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_morph = pymorph_lem(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [01:16<00:00, 117.68it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_morph = pymorph_lem(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем русский язык"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.ru import Russian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем объект класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Russian()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пишем функцию для лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_lemm(items):\n",
    "    result = []\n",
    "    for row in tqdm(items):\n",
    "        for item in row:\n",
    "            doc = nlp(item)\n",
    "            line = [token.lemma_ for token in doc]\n",
    "            result.append(line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустили"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21000/21000 [04:08<00:00, 84.46it/s] \n"
     ]
    }
   ],
   "source": [
    "X_train_spacy = spacy_lemm(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [01:47<00:00, 83.70it/s] \n"
     ]
    }
   ],
   "source": [
    "X_test_spacy = spacy_lemm(X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
